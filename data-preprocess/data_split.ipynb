{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = \"../data_duplicate/train_images_filtered_no_duplicate_transformed_1.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import imagehash\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       image_id  labels\n",
      "0                 723977410.jpg       3\n",
      "1                3193577634.jpg       1\n",
      "2                3349107107.jpg       3\n",
      "3                2933959901.jpg       0\n",
      "4                3020460837.jpg       4\n",
      "...                         ...     ...\n",
      "262845  3150477025_rotate_2.jpg       2\n",
      "262846    3150477025_hue1_2.jpg       2\n",
      "262847    3150477025_hue2_2.jpg       2\n",
      "262848    3150477025_hue3_2.jpg       2\n",
      "262849    3150477025_hue4_2.jpg       2\n",
      "\n",
      "[262850 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels\n",
      "3    15452\n",
      "1     3451\n",
      "2     3014\n",
      "4     2888\n",
      "0     1480\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "unique_labels = train_df.labels.value_counts()\n",
    "num_unique_labels = unique_labels.nunique()\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/Users/alexshienhowkhoo/Documents/NTU_BCG/NTU_BCG_Y3S1/Others/SC4000_Machine_Learning/SC4000_Project/SC4000_Machine_Learning/data_duplicate/train_images'\n",
    "img_paths = glob.glob(images_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "def add_random_noise(image):\n",
    "    # Lower standard deviation to reduce noise intensity\n",
    "    noise = np.random.normal(0, 10, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "def add_random_shadow(image):\n",
    "    top_y = image.shape[0] * np.random.uniform(0.3, 0.7)\n",
    "    bot_y = image.shape[0] * np.random.uniform(0.3, 0.7)\n",
    "    shadow_img = image.copy()\n",
    "    \n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    x = np.array([0, image.shape[1], image.shape[1], 0], dtype=np.int32)\n",
    "    y = np.array([top_y, top_y, bot_y, bot_y], dtype=np.int32)\n",
    "    pts = np.stack([x, y], axis=1)\n",
    "    cv2.fillPoly(mask, [pts], (255, 255, 255))\n",
    "    \n",
    "    shadow_ratio = np.random.uniform(0.3, 0.7)\n",
    "    shadow_img = cv2.addWeighted(shadow_img, shadow_ratio, mask, 1 - shadow_ratio, 0)\n",
    "    \n",
    "    return shadow_img\n",
    "\n",
    "def shear_image(image, shear_range=0.2):\n",
    "    rows, cols, ch = image.shape\n",
    "    dx = cols * np.random.uniform(-shear_range, shear_range)\n",
    "    \n",
    "    # Shear transformation matrix\n",
    "    shear_matrix = np.array([[1, dx / cols, 0],\n",
    "                             [0, 1, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Apply shear transformation\n",
    "    sheared_img = cv2.warpAffine(image, shear_matrix, (cols, rows))\n",
    "    return sheared_img\n",
    "\n",
    "def rotate_image(image, max_angle=30):\n",
    "    rows, cols, ch = image.shape\n",
    "    angle = np.random.uniform(-max_angle, max_angle)\n",
    "    \n",
    "    # Rotation transformation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    \n",
    "    # Apply rotation transformation\n",
    "    rotated_img = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n",
    "    return rotated_img\n",
    "\n",
    "def add_random_shadow_new(image):\n",
    "    # Copy the original image for the shadow effect\n",
    "    shadow_img = image.copy()\n",
    "    \n",
    "    # Horizontal shadow parameters\n",
    "    top_y = int(image.shape[0] * np.random.uniform(0.3, 0.7))\n",
    "    bot_y = int(image.shape[0] * np.random.uniform(0.3, 0.7))\n",
    "    \n",
    "    # Vertical shadow parameters\n",
    "    left_x = int(image.shape[1] * np.random.uniform(0.3, 0.7))\n",
    "    right_x = int(image.shape[1] * np.random.uniform(0.3, 0.7))\n",
    "\n",
    "    # Initialize mask for horizontal shadow\n",
    "    mask_horizontal = np.zeros_like(image, dtype=np.uint8)\n",
    "    x_horiz = np.array([0, image.shape[1], image.shape[1], 0], dtype=np.int32)\n",
    "    y_horiz = np.array([top_y, top_y, bot_y, bot_y], dtype=np.int32)\n",
    "    pts_horiz = np.stack([x_horiz, y_horiz], axis=1)\n",
    "    cv2.fillPoly(mask_horizontal, [pts_horiz], (255, 255, 255))\n",
    "\n",
    "    # Initialize mask for vertical shadow\n",
    "    mask_vertical = np.zeros_like(image, dtype=np.uint8)\n",
    "    x_vert = np.array([left_x, right_x, right_x, left_x], dtype=np.int32)\n",
    "    y_vert = np.array([0, 0, image.shape[0], image.shape[0]], dtype=np.int32)\n",
    "    pts_vert = np.stack([x_vert, y_vert], axis=1)\n",
    "    cv2.fillPoly(mask_vertical, [pts_vert], (255, 255, 255))\n",
    "\n",
    "    # Combine horizontal and vertical masks\n",
    "    combined_mask = cv2.bitwise_or(mask_horizontal, mask_vertical)\n",
    "\n",
    "    # Apply the shadow using the combined mask\n",
    "    shadow_ratio = np.random.uniform(0.3, 0.7)\n",
    "    shadow_img = cv2.addWeighted(shadow_img, shadow_ratio, combined_mask, 1 - shadow_ratio, 0)\n",
    "\n",
    "    return shadow_img\n",
    "\n",
    "def hueAdder1(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [175, 105, 70]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "\n",
    "def hueAdder2(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [85, -40, -67, 140]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "\n",
    "\n",
    "def hueAdder3(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [30, 150, 50]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "def hueAdder4(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [-67, 140]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "transformation_functions = [add_random_shadow, add_random_noise,add_random_shadow_new, shear_image, rotate_image, hueAdder1,hueAdder2,hueAdder3,hueAdder4]\n",
    "transformation_names = [\"shadow\", \"noise\", \"new_shadow\", \"shear\",\"rotate\", \"hue1\",\"hue2\",\"hue3\",\"hue4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Load the pandas table\n",
    "new_entries = []  # List to collect new rows\n",
    "\n",
    "for img_path in img_paths:\n",
    "        # Open the image\n",
    "        image = cv2.imread(img_path)\n",
    "        base_name_with_ext = os.path.basename(img_path)  # e.g., \"Right_37.jpg\"\n",
    "        \n",
    "        # Find corresponding row in the DataFrame\n",
    "        if base_name_with_ext not in train_df['image_id'].values:\n",
    "            print(f'{base_name_with_ext}')\n",
    "            print(f\"No entry found in train table for {base_name_with_ext}. Skipping.\")\n",
    "            os.remove(img_path)\n",
    "            continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/Users/alexshienhowkhoo/Documents/NTU_BCG/NTU_BCG_Y3S1/Others/SC4000_Machine_Learning/SC4000_Project/SC4000_Machine_Learning/data_duplicate/train_images'\n",
    "img_paths = glob.glob(images_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1900920171.jpg\n",
      "            image_id  labels\n",
      "7482  1900920171.jpg       2\n",
      "train-cmd-1992.jpg\n",
      "                 image_id  labels\n",
      "25324  train-cmd-1992.jpg       3\n",
      "1695222952.jpg\n",
      "             image_id  labels\n",
      "14882  1695222952.jpg       2\n",
      "1492381879.jpg\n",
      "             image_id  labels\n",
      "25223  1492381879.jpg       3\n",
      "1046703257.jpg\n",
      "             image_id  labels\n",
      "12692  1046703257.jpg       4\n",
      "train-cgm-738.jpg\n",
      "               image_id  labels\n",
      "6636  train-cgm-738.jpg       2\n",
      "train-cmd-2243.jpg\n",
      "                 image_id  labels\n",
      "25029  train-cmd-2243.jpg       3\n",
      "3968083899.jpg\n",
      "             image_id  labels\n",
      "16340  3968083899.jpg       0\n",
      "train-cbsd-913.jpg\n",
      "                 image_id  labels\n",
      "23192  train-cbsd-913.jpg       1\n",
      "206432986.jpg\n",
      "            image_id  labels\n",
      "17486  206432986.jpg       4\n",
      "1177346702.jpg\n",
      "             image_id  labels\n",
      "25802  1177346702.jpg       1\n",
      "447053671.jpg\n",
      "           image_id  labels\n",
      "3160  447053671.jpg       2\n",
      "1937546373.jpg\n",
      "             image_id  labels\n",
      "20138  1937546373.jpg       4\n",
      "train-cmd-2525.jpg\n",
      "                 image_id  labels\n",
      "10663  train-cmd-2525.jpg       3\n",
      "4149442480.jpg\n",
      "             image_id  labels\n",
      "25473  4149442480.jpg       3\n",
      "671937589.jpg\n",
      "           image_id  labels\n",
      "7370  671937589.jpg       3\n",
      "2013837502.jpg\n",
      "             image_id  labels\n",
      "13366  2013837502.jpg       3\n",
      "train-cmd-1038.jpg\n",
      "                 image_id  labels\n",
      "15851  train-cmd-1038.jpg       3\n",
      "2421207355.jpg\n",
      "             image_id  labels\n",
      "25541  2421207355.jpg       3\n",
      "1181678723.jpg\n",
      "             image_id  labels\n",
      "13701  1181678723.jpg       0\n",
      "1527846790.jpg\n",
      "             image_id  labels\n",
      "15031  1527846790.jpg       3\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(train_df[train_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage_id\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m base_name_with_ext])\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#print(train_df[train_df['image_id'] == base_name_with_ext][\"labels\"].values[0])\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(train_df[\u001b[43mtrain_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimage_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbase_name_with_ext\u001b[49m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Remove the extension from the base name\u001b[39;00m\n\u001b[1;32m     21\u001b[0m base_name \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(base_name_with_ext)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:344\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m invalid_comparison(lvalues, rvalues, op)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m lvalues\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(rvalues, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43mcomp_method_OBJECT_ARRAY\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(lvalues, rvalues, op, is_cmp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:129\u001b[0m, in \u001b[0;36mcomp_method_OBJECT_ARRAY\u001b[0;34m(op, x, y)\u001b[0m\n\u001b[1;32m    127\u001b[0m     result \u001b[38;5;241m=\u001b[39m libops\u001b[38;5;241m.\u001b[39mvec_compare(x\u001b[38;5;241m.\u001b[39mravel(), y\u001b[38;5;241m.\u001b[39mravel(), op)\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 129\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mlibops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscalar_compare\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mreshape(x\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Load the pandas table\n",
    "new_entries = []  # List to collect new rows\n",
    "\n",
    "for img_path in img_paths:\n",
    "    try:\n",
    "        # Open the image\n",
    "        image = cv2.imread(img_path)\n",
    "        base_name_with_ext = os.path.basename(img_path)  # e.g., \"Right_37.jpg\"\n",
    "        print(base_name_with_ext)\n",
    "        print(train_df[train_df['image_id'] == base_name_with_ext])\n",
    "        #print(train_df[train_df['image_id'] == base_name_with_ext][\"labels\"].values[0])\n",
    "        label = int(train_df[train_df['image_id'] == base_name_with_ext][\"labels\"].values[0])\n",
    "        \n",
    "\n",
    "        # Remove the extension from the base name\n",
    "        base_name = os.path.splitext(base_name_with_ext)[0]\n",
    "        \n",
    "        # Define the output directory as the original image directory\n",
    "        output_image_dir = os.path.dirname(img_path)\n",
    "        \n",
    "        # Apply each transformation function and save as a new image\n",
    "        for func, tname in zip(transformation_functions, transformation_names):\n",
    "            # Apply the transformation\n",
    "            transformed_image = func(image)\n",
    "            \n",
    "            # Convert to RGB and save as JPEG\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # Generate new file path using base name, transformation name, and labels name\n",
    "            new_image_name = f\"{base_name}_{tname}_{label}.jpg\"\n",
    "            new_image_path = os.path.join(output_image_dir, new_image_name)\n",
    "            pil_image.save(new_image_path, format='JPEG')\n",
    "            \n",
    "            # Add new entry to the list for the updated DataFrame\n",
    "            new_entries.append({'image_id': new_image_name, 'labels': label})\n",
    "    \n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping unrecognized or corrupted file: {img_path}\")\n",
    "\n",
    "# Append the new entries to train_df\n",
    "new_entries_df = pd.DataFrame(new_entries)\n",
    "train_df = pd.concat([train_df, new_entries_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "train_df.to_csv(\"../data_duplicate/train_images_filtered_no_duplicate_transformed.csv\", index=False)  # Replace with your desired path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df\n",
    "train_df.to_csv(\"../data_duplicate/train_images_filtered_no_duplicate_transformed_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged_train.csv\n",
      "\u001b[34moriginal_data copy\u001b[m\u001b[m/\n",
      "\u001b[34mtrain_images\u001b[m\u001b[m/\n",
      "\u001b[34mtrain_images copy\u001b[m\u001b[m/\n",
      "train_images.zip\n",
      "train_images_filtered_no_duplicate_transformed.csv\n",
      "train_images_filtered_no_duplicate_transformed_1.csv\n",
      "train_images_filtered_no_duplicates.csv\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from skimage.io import imread\n",
    "# import os\n",
    "# # Step 1: Load Images\n",
    "# image_paths = \"../dataset/train_images/\"  \n",
    "\n",
    "# smote_output_folder = \"../dataset/smote_images/\"   \n",
    "# os.makedirs(smote_output_folder, exist_ok=True)\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for idx, row in train_df.iterrows():\n",
    "#     image_id = row['image_id']\n",
    "#     label = row['label']\n",
    "    \n",
    "#     # Load each image, assuming file path format is image_paths + image_id + '.jpg'\n",
    "#     image = imread(f\"{image_paths}{image_id}\")\n",
    "    \n",
    "#     # Append image and label\n",
    "#     X.append(image)\n",
    "#     y.append(label)\n",
    "\n",
    "# X = np.array(X)  # Convert to numpy array\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 2: Flatten images if necessary\n",
    "# X_flattened = X.reshape(X.shape[0], -1)  # Flatten to 1D if needed\n",
    "\n",
    "# # Step 3: Apply SMOTE\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# X_resampled_flattened, y_resampled = smote.fit_resample(X_flattened, y)\n",
    "\n",
    "# # Step 4: Reshape back if you flattened\n",
    "# image_shape = X.shape[1:]  # Original shape\n",
    "# X_resampled = X_resampled_flattened.reshape(-1, *image_shape)\n",
    "\n",
    "# # Step 5: Create DataFrame with resampled data\n",
    "# # Optionally, create synthetic `image_id`s for new samples or add a prefix to differentiate\n",
    "# df_resampled = pd.DataFrame({\n",
    "#     'image_id': [f\"{i}_synthetic\" for i in range(len(y_resampled))],  # New synthetic IDs\n",
    "#     'class_label': y_resampled\n",
    "# })\n",
    "\n",
    "# # Save SMOTE-generated images\n",
    "# for i, img_array in enumerate(X_resampled[len(X):]):  # Only new images\n",
    "#     img = Image.fromarray(img_array.astype('uint8'), 'RGB')  # Convert numpy array to Image\n",
    "#     img.save(f\"{smote_output_folder}/smote_image_{i}.jpg\")  # Save with unique name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# desired_majority_class_size = 6000\n",
    "\n",
    "# class_counts = df_train[\"labels\"].value_counts()\n",
    "# undersample_strategy = {class_counts.idxmax(): desired_majority_class_size}\n",
    "\n",
    "# rus = RandomUnderSampler(sampling_strategy=undersample_strategy, random_state=109)\n",
    "# X_under, y_under = rus.fit_resample(\n",
    "#     df_train[\"image_id\"].values.reshape(-1, 1), df_train[\"labels\"].values\n",
    "# )\n",
    "\n",
    "# desired_minority_class_size = 6000\n",
    "\n",
    "# ros = RandomOverSampler(\n",
    "#     sampling_strategy={\n",
    "#         label: desired_minority_class_size\n",
    "#         for label in class_counts.index\n",
    "#         if class_counts[label] < desired_minority_class_size\n",
    "#     },\n",
    "#     random_state=109,\n",
    "# )\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_under, y_under)\n",
    "\n",
    "# df_train_resampled = pd.DataFrame(\n",
    "#     {\"image_id\": X_resampled.flatten(), \"labels\": y_resampled}\n",
    "# )\n",
    "\n",
    "# # Check the new class distribution\n",
    "# print(df_train_resampled[\"labels\"].value_counts())\n",
    "\n",
    "# df_train_resampled.reset_index(drop=True, inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
