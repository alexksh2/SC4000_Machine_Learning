{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9f09e3f-bed8-4ed6-a926-89fa5fe01f2d",
   "metadata": {},
   "source": [
    "## Import libraries for ensemble techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e6b13e4-dda8-477f-9a2e-3b5ef9029a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    fbeta_score,\n",
    "    log_loss,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace0551-007d-41f6-ac2e-f0d60c8866a2",
   "metadata": {},
   "source": [
    "## Load valid_df and test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eabaa16c-3823-4b34-9ce1-c0a3bbc4343e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1611662564_noise_4.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801551318_hue3_4.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cbb-434.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3078964330_hue2_4.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175989862_hue4_2.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 image_id  labels\n",
       "0  1611662564_noise_4.jpg       4\n",
       "1    801551318_hue3_4.jpg       4\n",
       "2       train-cbb-434.jpg       0\n",
       "3   3078964330_hue2_4.jpg       4\n",
       "4    175989862_hue4_2.jpg       2"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = pd.read_csv(\n",
    "    \"/home/samic_yongjian/temp/SC4000_Machine_Learning/data/valid_df.csv\"\n",
    ")\n",
    "valid_df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9af8d6c-ca13-4b17-9938-081dd89e7725",
   "metadata": {},
   "source": [
    "### TEST SET !!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4adb04cb-af1a-4868-8045-3053a0ebe042",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\n",
    "    \"/home/samic_yongjian/temp/SC4000_Machine_Learning/data/test_df.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cc1e67a-3222-43dc-9986-5846e48a31af",
   "metadata": {},
   "source": [
    "## Load csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ab6185-5e0c-4181-ab8a-0fc30d5e1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = [\n",
    "    # \"/home/samic_yongjian/temp/SC4000_Machine_Learning/output/vit_v2/20241104_164221/validation_probabilities.csv\",\n",
    "    \"/home/samic_yongjian/temp/SC4000_Machine_Learning/output/vit/20241103_190631/validation_probabilities.csv\",\n",
    "    \"/home/samic_yongjian/temp/SC4000_Machine_Learning/output/resnext/20241103_232814/best_validation_probabilities.csv\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1ed032e-0fd8-4303-a859-a9da424ee8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_count = len(csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11530dd8-616a-4d39-82f1-ae73c01b1dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,file in enumerate(csv_files): \n",
    "    if i == 0: \n",
    "        merged_df = pd.read_csv(file)\n",
    "        #move the image_id column to the first\n",
    "        image_name = merged_df.columns[-1]\n",
    "        merged_df = merged_df[[image_name] + merged_df.columns[:-1].tolist()]\n",
    "        #sort the order of validation true labels and get the labels\n",
    "        valid_df = merged_df.merge(valid_df, on = 'image_id', how = 'left')\n",
    "        valid_df = valid_df[['image_id', 'labels']]\n",
    "        true_val_labels = valid_df['labels'].values\n",
    "    else: \n",
    "        df = pd.read_csv(file)\n",
    "        merged_df = merged_df.merge(df, on = 'image_id', how = 'left', suffixes = ('', '_model'+str(i+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b95834c-ec8e-4fb0-a11e-d43350915814",
   "metadata": {},
   "source": [
    "## Initialize Eval Table for Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "898f129c-2160-4c36-a960-d056376f0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame with specific column names\n",
    "columns = ['Method','Log Loss', 'Accuracy', 'Precision', 'Recall', 'F1 Score', 'F2 Score']\n",
    "val_ensemble_df = pd.DataFrame(columns=columns)\n",
    "test_ensemble_df = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5061f78c-236b-4c8d-ac1b-de5736343b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ensemble (ensemble_df, true_labels, pred_labels, pred_probs, method, mode):\n",
    "    logloss = log_loss(true_labels, pred_probs)\n",
    "    accuracy = accuracy_score(true_labels, pred_labels)\n",
    "    precision = precision_score(true_labels, pred_labels, average=\"weighted\")\n",
    "    recall = recall_score(true_labels, pred_labels, average=\"weighted\")\n",
    "    f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n",
    "    f2 = fbeta_score(true_labels, pred_labels, beta=2, average=\"weighted\")\n",
    "\n",
    "    print(f\"Metrics for {method} on {mode} set\")\n",
    "    print(f\"Log Loss: {logloss:.4f}\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    print(f\"F2 Score: {f2:.4f}\")\n",
    "    \n",
    "    ensemble_df.loc[len(ensemble_df)] = [method, logloss, accuracy, precision, recall, f1, f2]\n",
    "    return ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aace919b-8d2c-4bdb-8e96-2a144abe9b7e",
   "metadata": {},
   "source": [
    "## Load softmax probabilities\n",
    "Note: Assuming that all csv files contain a last column stating the image_ids. Here, we only extract the true labels from the first file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e081502-e9d8-48f1-852e-2654ccc1c6e6",
   "metadata": {},
   "source": [
    "## Ensemble 1 - Soft Voting: Averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a715bcb4-e5e0-41c9-b548-f29300e8923f",
   "metadata": {},
   "outputs": [],
   "source": [
    "average_df = pd.DataFrame()\n",
    "\n",
    "average_df['image_id'] = merged_df['image_id']\n",
    "average_df['avg_prob_class0'] = merged_df[['prob_class_0'] + [f'prob_class_0_model{i+2}' for i in range(model_count - 1)]].mean(axis=1)\n",
    "average_df['avg_prob_class1'] = merged_df[['prob_class_1'] + [f'prob_class_1_model{i+2}' for i in range(model_count - 1)]].mean(axis=1)\n",
    "average_df['avg_prob_class2'] = merged_df[['prob_class_2'] + [f'prob_class_2_model{i+2}' for i in range(model_count - 1)]].mean(axis=1)\n",
    "average_df['avg_prob_class3'] = merged_df[['prob_class_3'] + [f'prob_class_3_model{i+2}' for i in range(model_count - 1)]].mean(axis=1)\n",
    "average_df['avg_prob_class4'] = merged_df[['prob_class_4'] + [f'prob_class_4_model{i+2}' for i in range(model_count - 1)]].mean(axis=1)\n",
    "\n",
    "average_df.to_csv('test_average.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52d8c1c5-637f-43d1-9f95-8264f57429ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for logloss \n",
    "pred_val_probs = np.array([average_df.iloc[i, 1:].values for i in range(len(average_df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9d9715df-2a8d-4df3-8851-7004fa2dd54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the column index (integer) of the maximum value in each row, starting from the second column\n",
    "pred_val_labels = average_df.values[:, 1:].argmax(axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bfbdf69b-133c-431e-ba1b-0b13c23c11c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for Averaging on Val set\n",
      "Log Loss: 0.3616\n",
      "Accuracy: 0.8895\n",
      "Precision: 0.8896\n",
      "Recall: 0.8895\n",
      "F1 Score: 0.8894\n",
      "F2 Score: 0.8894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/samic_yongjian/miniconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:2981: UserWarning: The y_pred values do not sum to one. Starting from 1.5 thiswill result in an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "val_ensemble_df = add_ensemble(val_ensemble_df, true_val_labels, pred_val_labels, pred_val_probs, \"Averaging\", \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "245313ae-665e-4cb4-a8c2-ddbf4c4b32a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Averaging</td>\n",
       "      <td>0.361553</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.889418</td>\n",
       "      <td>0.889443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Method  Log Loss  Accuracy  Precision    Recall  F1 Score  F2 Score\n",
       "0  Averaging  0.361553  0.889527   0.889641  0.889527  0.889418  0.889443"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af4c1a-3cf4-4567-ad28-3cbd9182198b",
   "metadata": {},
   "source": [
    "Remember add for test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a064f6e-c8bb-4a94-8e3f-53c48a6e65f9",
   "metadata": {},
   "source": [
    "## Ensemble 2 - Stacking Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3034c25e-a857-4ffc-8052-8016a38a6548",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>prob_class_0</th>\n",
       "      <th>prob_class_1</th>\n",
       "      <th>prob_class_2</th>\n",
       "      <th>prob_class_3</th>\n",
       "      <th>prob_class_4</th>\n",
       "      <th>prob_class_0_model2</th>\n",
       "      <th>prob_class_1_model2</th>\n",
       "      <th>prob_class_2_model2</th>\n",
       "      <th>prob_class_3_model2</th>\n",
       "      <th>prob_class_4_model2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1611662564_noise_4.jpg</td>\n",
       "      <td>0.010940</td>\n",
       "      <td>0.000916</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000818</td>\n",
       "      <td>9.873169e-01</td>\n",
       "      <td>0.000495</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.998050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>801551318_hue3_4.jpg</td>\n",
       "      <td>0.005787</td>\n",
       "      <td>0.020777</td>\n",
       "      <td>0.001658</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>9.714059e-01</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.015886</td>\n",
       "      <td>0.036767</td>\n",
       "      <td>0.052547</td>\n",
       "      <td>0.894417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train-cbb-434.jpg</td>\n",
       "      <td>0.998480</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>7.728260e-07</td>\n",
       "      <td>0.961509</td>\n",
       "      <td>0.037866</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.000096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3078964330_hue2_4.jpg</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.007819</td>\n",
       "      <td>0.007128</td>\n",
       "      <td>0.001396</td>\n",
       "      <td>9.834493e-01</td>\n",
       "      <td>0.014867</td>\n",
       "      <td>0.020336</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.964374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175989862_hue4_2.jpg</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.002175</td>\n",
       "      <td>0.980255</td>\n",
       "      <td>0.012771</td>\n",
       "      <td>3.048500e-03</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.999523</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14795</th>\n",
       "      <td>3353595234_hue2_2.jpg</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.999971</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>8.161075e-06</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.999460</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.000091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14796</th>\n",
       "      <td>train-cmd-928_shear_3.jpg</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.999082</td>\n",
       "      <td>8.746736e-06</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.999823</td>\n",
       "      <td>0.000088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14797</th>\n",
       "      <td>471996434_hue4_4.jpg</td>\n",
       "      <td>0.004226</td>\n",
       "      <td>0.985866</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.003628</td>\n",
       "      <td>5.427785e-03</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.004871</td>\n",
       "      <td>0.982910</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.009577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14798</th>\n",
       "      <td>3939876859_new_shadow_0.jpg</td>\n",
       "      <td>0.999825</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>3.443130e-05</td>\n",
       "      <td>0.546116</td>\n",
       "      <td>0.006218</td>\n",
       "      <td>0.033348</td>\n",
       "      <td>0.016470</td>\n",
       "      <td>0.397849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14799</th>\n",
       "      <td>train-cgm-258_shadow_2.jpg</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.999804</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1.663613e-05</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.998827</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14800 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          image_id  prob_class_0  prob_class_1  prob_class_2  \\\n",
       "0           1611662564_noise_4.jpg      0.010940      0.000916      0.000009   \n",
       "1             801551318_hue3_4.jpg      0.005787      0.020777      0.001658   \n",
       "2                train-cbb-434.jpg      0.998480      0.001054      0.000334   \n",
       "3            3078964330_hue2_4.jpg      0.000208      0.007819      0.007128   \n",
       "4             175989862_hue4_2.jpg      0.001751      0.002175      0.980255   \n",
       "...                            ...           ...           ...           ...   \n",
       "14795        3353595234_hue2_2.jpg      0.000005      0.000011      0.999971   \n",
       "14796    train-cmd-928_shear_3.jpg      0.000020      0.000865      0.000025   \n",
       "14797         471996434_hue4_4.jpg      0.004226      0.985866      0.000853   \n",
       "14798  3939876859_new_shadow_0.jpg      0.999825      0.000009      0.000017   \n",
       "14799   train-cgm-258_shadow_2.jpg      0.000047      0.000069      0.999804   \n",
       "\n",
       "       prob_class_3  prob_class_4  prob_class_0_model2  prob_class_1_model2  \\\n",
       "0          0.000818  9.873169e-01             0.000495             0.001323   \n",
       "1          0.000371  9.714059e-01             0.000383             0.015886   \n",
       "2          0.000131  7.728260e-07             0.961509             0.037866   \n",
       "3          0.001396  9.834493e-01             0.014867             0.020336   \n",
       "4          0.012771  3.048500e-03             0.000245             0.000017   \n",
       "...             ...           ...                  ...                  ...   \n",
       "14795      0.000005  8.161075e-06             0.000004             0.000181   \n",
       "14796      0.999082  8.746736e-06             0.000001             0.000041   \n",
       "14797      0.003628  5.427785e-03             0.000265             0.004871   \n",
       "14798      0.000116  3.443130e-05             0.546116             0.006218   \n",
       "14799      0.000063  1.663613e-05             0.000038             0.000218   \n",
       "\n",
       "       prob_class_2_model2  prob_class_3_model2  prob_class_4_model2  \n",
       "0                 0.000080             0.000052             0.998050  \n",
       "1                 0.036767             0.052547             0.894417  \n",
       "2                 0.000372             0.000157             0.000096  \n",
       "3                 0.000385             0.000038             0.964374  \n",
       "4                 0.999523             0.000211             0.000005  \n",
       "...                    ...                  ...                  ...  \n",
       "14795             0.999460             0.000265             0.000091  \n",
       "14796             0.000048             0.999823             0.000088  \n",
       "14797             0.982910             0.002376             0.009577  \n",
       "14798             0.033348             0.016470             0.397849  \n",
       "14799             0.998827             0.000030             0.000888  \n",
       "\n",
       "[14800 rows x 11 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2873a345-eb47-43c0-86c5-2bcecc8613f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the arrays of softmax probabilities \n",
    "model_probs = []\n",
    "for j in range (model_count): \n",
    "    if j == 0: \n",
    "        column_names = [f'prob_class_{i}' for i in range(5)]\n",
    "    else: \n",
    "        column_names = [f'prob_class_{i}_model{j+1}' for i in range(5)]\n",
    "    model_prob = merged_df[column_names].values\n",
    "    model_probs.append(model_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "759058d1-7b5b-4a55-836f-7cbf1ed96b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all model probabilities horizontally\n",
    "X_stacked = np.hstack(model_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c41f851f-f42d-45f6-9b0a-aa87a56f155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the logistic regression model\n",
    "logistic_classifier = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "logistic_classifier.fit(X_stacked, true_val_labels)\n",
    "# Make predictions on the validation set\n",
    "log_val_predlabel = logistic_classifier.predict(X_stacked)\n",
    "log_val_predprob = logistic_classifier.predict_proba(X_stacked)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "41626287-6374-497a-b114-290154a24e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for LogReg on Val set\n",
      "Log Loss: 0.3507\n",
      "Accuracy: 0.8936\n",
      "Precision: 0.8936\n",
      "Recall: 0.8936\n",
      "F1 Score: 0.8935\n",
      "F2 Score: 0.8936\n"
     ]
    }
   ],
   "source": [
    "val_ensemble_df = add_ensemble(val_ensemble_df, true_val_labels, log_val_predlabel, log_val_predprob, \"LogReg\", \"Val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b3560208-7a12-42cd-a3c8-05d141b6cb86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Method</th>\n",
       "      <th>Log Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Averaging</td>\n",
       "      <td>0.361553</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.889641</td>\n",
       "      <td>0.889527</td>\n",
       "      <td>0.889418</td>\n",
       "      <td>0.889443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.350727</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.893632</td>\n",
       "      <td>0.893649</td>\n",
       "      <td>0.893544</td>\n",
       "      <td>0.893584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Method  Log Loss  Accuracy  Precision    Recall  F1 Score  F2 Score\n",
       "0  Averaging  0.361553  0.889527   0.889641  0.889527  0.889418  0.889443\n",
       "1     LogReg  0.350727  0.893649   0.893632  0.893649  0.893544  0.893584"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ensemble_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d66e4a-42b9-43ea-ac64-12b3009ca7c7",
   "metadata": {},
   "source": [
    "Remember add for test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b088f9bf-6378-4cae-ade1-ca952d3fe4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c79023-66f0-4205-9218-fe6744261aca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c42e66-c58e-4de1-95e6-99ed4a18bbb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26292d1-857d-4fd0-9530-3a12e1399175",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
