{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV_PATH = \"../data_duplicate/train_images_filtered_no_duplicates.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import imagehash\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV_PATH)\n",
    "print(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = train_df.labels.value_counts()\n",
    "num_unique_labels = unique_labels.nunique()\n",
    "print(unique_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = '/Users/alexshienhowkhoo/Documents/NTU_BCG/NTU_BCG_Y3S1/Others/SC4000_Machine_Learning/SC4000_Project/SC4000_Machine_Learning/data_duplicate/train_images'\n",
    "img_paths = glob.glob(images_path + '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import random\n",
    "\n",
    "def add_random_noise(image):\n",
    "    # Lower standard deviation to reduce noise intensity\n",
    "    noise = np.random.normal(0, 10, image.shape).astype(np.uint8)\n",
    "    noisy_image = cv2.add(image, noise)\n",
    "    return np.clip(noisy_image, 0, 255).astype(np.uint8)\n",
    "\n",
    "def add_random_shadow(image):\n",
    "    top_y = image.shape[0] * np.random.uniform(0.3, 0.7)\n",
    "    bot_y = image.shape[0] * np.random.uniform(0.3, 0.7)\n",
    "    shadow_img = image.copy()\n",
    "    \n",
    "    mask = np.zeros_like(image, dtype=np.uint8)\n",
    "    x = np.array([0, image.shape[1], image.shape[1], 0], dtype=np.int32)\n",
    "    y = np.array([top_y, top_y, bot_y, bot_y], dtype=np.int32)\n",
    "    pts = np.stack([x, y], axis=1)\n",
    "    cv2.fillPoly(mask, [pts], (255, 255, 255))\n",
    "    \n",
    "    shadow_ratio = np.random.uniform(0.3, 0.7)\n",
    "    shadow_img = cv2.addWeighted(shadow_img, shadow_ratio, mask, 1 - shadow_ratio, 0)\n",
    "    \n",
    "    return shadow_img\n",
    "\n",
    "def shear_image(image, shear_range=0.2):\n",
    "    rows, cols, ch = image.shape\n",
    "    dx = cols * np.random.uniform(-shear_range, shear_range)\n",
    "    \n",
    "    # Shear transformation matrix\n",
    "    shear_matrix = np.array([[1, dx / cols, 0],\n",
    "                             [0, 1, 0]], dtype=np.float32)\n",
    "    \n",
    "    # Apply shear transformation\n",
    "    sheared_img = cv2.warpAffine(image, shear_matrix, (cols, rows))\n",
    "    return sheared_img\n",
    "\n",
    "def rotate_image(image, max_angle=30):\n",
    "    rows, cols, ch = image.shape\n",
    "    angle = np.random.uniform(-max_angle, max_angle)\n",
    "    \n",
    "    # Rotation transformation matrix\n",
    "    rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "    \n",
    "    # Apply rotation transformation\n",
    "    rotated_img = cv2.warpAffine(image, rotation_matrix, (cols, rows))\n",
    "    return rotated_img\n",
    "\n",
    "def add_random_shadow_new(image):\n",
    "    # Copy the original image for the shadow effect\n",
    "    shadow_img = image.copy()\n",
    "    \n",
    "    # Horizontal shadow parameters\n",
    "    top_y = int(image.shape[0] * np.random.uniform(0.3, 0.7))\n",
    "    bot_y = int(image.shape[0] * np.random.uniform(0.3, 0.7))\n",
    "    \n",
    "    # Vertical shadow parameters\n",
    "    left_x = int(image.shape[1] * np.random.uniform(0.3, 0.7))\n",
    "    right_x = int(image.shape[1] * np.random.uniform(0.3, 0.7))\n",
    "\n",
    "    # Initialize mask for horizontal shadow\n",
    "    mask_horizontal = np.zeros_like(image, dtype=np.uint8)\n",
    "    x_horiz = np.array([0, image.shape[1], image.shape[1], 0], dtype=np.int32)\n",
    "    y_horiz = np.array([top_y, top_y, bot_y, bot_y], dtype=np.int32)\n",
    "    pts_horiz = np.stack([x_horiz, y_horiz], axis=1)\n",
    "    cv2.fillPoly(mask_horizontal, [pts_horiz], (255, 255, 255))\n",
    "\n",
    "    # Initialize mask for vertical shadow\n",
    "    mask_vertical = np.zeros_like(image, dtype=np.uint8)\n",
    "    x_vert = np.array([left_x, right_x, right_x, left_x], dtype=np.int32)\n",
    "    y_vert = np.array([0, 0, image.shape[0], image.shape[0]], dtype=np.int32)\n",
    "    pts_vert = np.stack([x_vert, y_vert], axis=1)\n",
    "    cv2.fillPoly(mask_vertical, [pts_vert], (255, 255, 255))\n",
    "\n",
    "    # Combine horizontal and vertical masks\n",
    "    combined_mask = cv2.bitwise_or(mask_horizontal, mask_vertical)\n",
    "\n",
    "    # Apply the shadow using the combined mask\n",
    "    shadow_ratio = np.random.uniform(0.3, 0.7)\n",
    "    shadow_img = cv2.addWeighted(shadow_img, shadow_ratio, combined_mask, 1 - shadow_ratio, 0)\n",
    "\n",
    "    return shadow_img\n",
    "\n",
    "def hueAdder1(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [175, 105, 70]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "\n",
    "def hueAdder2(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [85, -40, -67, 140]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "\n",
    "\n",
    "def hueAdder3(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [30, 150, 50]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "def hueAdder4(ori_img, saturation_boost=1.5, brightness_boost=0.9):\n",
    "    img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "    hue_value_list = [-67, 140]\n",
    "    hue_value = random.choice(hue_value_list)\n",
    "    \n",
    "    # Apply hue adjustment\n",
    "    img_hsv[:, :, 0] = (img_hsv[:, :, 0] + hue_value) % 180\n",
    "    \n",
    "    # Boost saturation and adjust brightness to make the hue more prominent\n",
    "    img_hsv[:, :, 1] = np.clip(img_hsv[:, :, 1] * saturation_boost, 0, 255)\n",
    "    img_hsv[:, :, 2] = np.clip(img_hsv[:, :, 2] * brightness_boost, 0, 255)\n",
    "    \n",
    "    # Convert back to RGB\n",
    "    enhanced_img = cv2.cvtColor(img_hsv, cv2.COLOR_HSV2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "transformation_functions = [add_random_shadow, add_random_noise,add_random_shadow_new, shear_image, rotate_image, hueAdder1,hueAdder2,hueAdder3,hueAdder4]\n",
    "transformation_names = [\"shadow\", \"noise\", \"new_shadow\", \"shear\",\"rotate\", \"hue1\",\"hue2\",\"hue3\",\"hue4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "# Load the pandas table\n",
    "new_entries = []  # List to collect new rows\n",
    "\n",
    "for img_path in img_paths:\n",
    "    try:\n",
    "        # Open the image\n",
    "        image = cv2.imread(img_path)\n",
    "        base_name_with_ext = os.path.basename(img_path)  # e.g., \"Right_37.jpg\"\n",
    "        \n",
    "        # Find corresponding row in the DataFrame\n",
    "        if base_name_with_ext not in train_df['image_id'].values:\n",
    "            print(f'{base_name_with_ext}')\n",
    "            print(f\"No entry found in train table for {base_name_with_ext}. Skipping.\")\n",
    "            os.remove(img_path)\n",
    "            continue\n",
    "        \n",
    "        label = train_df[train_df['image_id'] == base_name_with_ext][\"labels\"].values[0]\n",
    "\n",
    "        # Remove the extension from the base name\n",
    "        base_name = os.path.splitext(base_name_with_ext)[0]\n",
    "        \n",
    "        # Define the output directory as the original image directory\n",
    "        output_image_dir = os.path.dirname(img_path)\n",
    "        \n",
    "        # Apply each transformation function and save as a new image\n",
    "        for func, tname in zip(transformation_functions, transformation_names):\n",
    "            # Apply the transformation\n",
    "            transformed_image = func(image)\n",
    "            \n",
    "            # Convert to RGB and save as JPEG\n",
    "            pil_image = Image.fromarray(cv2.cvtColor(transformed_image, cv2.COLOR_BGR2RGB))\n",
    "            \n",
    "            # Generate new file path using base name, transformation name, and labels name\n",
    "            new_image_name = f\"{base_name}_{tname}_{label}.jpg\"\n",
    "            new_image_path = os.path.join(output_image_dir, new_image_name)\n",
    "            pil_image.save(new_image_path, format='JPEG')\n",
    "            \n",
    "            # Add new entry to the list for the updated DataFrame\n",
    "            new_entries.append({'image_id': new_image_name, 'labels': label})\n",
    "    \n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"Skipping unrecognized or corrupted file: {img_path}\")\n",
    "\n",
    "# Append the new entries to train_df\n",
    "new_entries_df = pd.DataFrame(new_entries)\n",
    "train_df = pd.concat([train_df, new_entries_df], ignore_index=True)\n",
    "\n",
    "# Save the updated DataFrame to a new CSV file\n",
    "train_df.to_csv(\"../data_duplicate/train_images_filtered_no_duplicate_transformed.csv\", index=False)  # Replace with your desired path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df\n",
    "train_df.to_csv(\"../data_duplicate/train_images_filtered_no_duplicate_transformed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# from skimage.io import imread\n",
    "# import os\n",
    "# # Step 1: Load Images\n",
    "# image_paths = \"../dataset/train_images/\"  \n",
    "\n",
    "# smote_output_folder = \"../dataset/smote_images/\"   \n",
    "# os.makedirs(smote_output_folder, exist_ok=True)\n",
    "\n",
    "# X = []\n",
    "# y = []\n",
    "\n",
    "# for idx, row in train_df.iterrows():\n",
    "#     image_id = row['image_id']\n",
    "#     label = row['label']\n",
    "    \n",
    "#     # Load each image, assuming file path format is image_paths + image_id + '.jpg'\n",
    "#     image = imread(f\"{image_paths}{image_id}\")\n",
    "    \n",
    "#     # Append image and label\n",
    "#     X.append(image)\n",
    "#     y.append(label)\n",
    "\n",
    "# X = np.array(X)  # Convert to numpy array\n",
    "# y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Step 2: Flatten images if necessary\n",
    "# X_flattened = X.reshape(X.shape[0], -1)  # Flatten to 1D if needed\n",
    "\n",
    "# # Step 3: Apply SMOTE\n",
    "# smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "# X_resampled_flattened, y_resampled = smote.fit_resample(X_flattened, y)\n",
    "\n",
    "# # Step 4: Reshape back if you flattened\n",
    "# image_shape = X.shape[1:]  # Original shape\n",
    "# X_resampled = X_resampled_flattened.reshape(-1, *image_shape)\n",
    "\n",
    "# # Step 5: Create DataFrame with resampled data\n",
    "# # Optionally, create synthetic `image_id`s for new samples or add a prefix to differentiate\n",
    "# df_resampled = pd.DataFrame({\n",
    "#     'image_id': [f\"{i}_synthetic\" for i in range(len(y_resampled))],  # New synthetic IDs\n",
    "#     'class_label': y_resampled\n",
    "# })\n",
    "\n",
    "# # Save SMOTE-generated images\n",
    "# for i, img_array in enumerate(X_resampled[len(X):]):  # Only new images\n",
    "#     img = Image.fromarray(img_array.astype('uint8'), 'RGB')  # Convert numpy array to Image\n",
    "#     img.save(f\"{smote_output_folder}/smote_image_{i}.jpg\")  # Save with unique name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# desired_majority_class_size = 6000\n",
    "\n",
    "# class_counts = df_train[\"labels\"].value_counts()\n",
    "# undersample_strategy = {class_counts.idxmax(): desired_majority_class_size}\n",
    "\n",
    "# rus = RandomUnderSampler(sampling_strategy=undersample_strategy, random_state=109)\n",
    "# X_under, y_under = rus.fit_resample(\n",
    "#     df_train[\"image_id\"].values.reshape(-1, 1), df_train[\"labels\"].values\n",
    "# )\n",
    "\n",
    "# desired_minority_class_size = 6000\n",
    "\n",
    "# ros = RandomOverSampler(\n",
    "#     sampling_strategy={\n",
    "#         label: desired_minority_class_size\n",
    "#         for label in class_counts.index\n",
    "#         if class_counts[label] < desired_minority_class_size\n",
    "#     },\n",
    "#     random_state=109,\n",
    "# )\n",
    "# X_resampled, y_resampled = ros.fit_resample(X_under, y_under)\n",
    "\n",
    "# df_train_resampled = pd.DataFrame(\n",
    "#     {\"image_id\": X_resampled.flatten(), \"labels\": y_resampled}\n",
    "# )\n",
    "\n",
    "# # Check the new class distribution\n",
    "# print(df_train_resampled[\"labels\"].value_counts())\n",
    "\n",
    "# df_train_resampled.reset_index(drop=True, inplace=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
